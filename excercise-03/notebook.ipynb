{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset context\n",
    "- Dataset Context: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "- It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "- This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "- It contains only numerical input variables which are the result of a PCA transformation. Features V1, V2, … V28 are the principal components obtained with PCA\n",
    "- The only features which have not been transformed with PCA are 'Time' and 'Amount'\n",
    "- Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset.\n",
    "- The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "- Dùng các model: Decision trees, Deep learning, Random forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df_original = pd.read_csv(\"./data/creditcard.csv\")\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(df_original, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(\"eda_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the profiling report:\n",
    "- Dataset has 773 (0.3%) duplicate rows\n",
    "- `Class` is highly correlated with 6 other attributes: V10, V11, V12, V14, V16, V17, V18.\n",
    "- `Class` is highly imbalanced with 98.2% of the sample has value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94811.077600</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>-0.004135</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>-0.002966</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>88.472687</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47481.047891</td>\n",
       "      <td>1.948026</td>\n",
       "      <td>1.646703</td>\n",
       "      <td>1.508682</td>\n",
       "      <td>1.414184</td>\n",
       "      <td>1.377008</td>\n",
       "      <td>1.331931</td>\n",
       "      <td>1.227664</td>\n",
       "      <td>1.179054</td>\n",
       "      <td>1.095492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723909</td>\n",
       "      <td>0.724550</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>0.605627</td>\n",
       "      <td>0.521220</td>\n",
       "      <td>0.482053</td>\n",
       "      <td>0.395744</td>\n",
       "      <td>0.328027</td>\n",
       "      <td>250.399437</td>\n",
       "      <td>0.040796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54204.750000</td>\n",
       "      <td>-0.915951</td>\n",
       "      <td>-0.600321</td>\n",
       "      <td>-0.889682</td>\n",
       "      <td>-0.850134</td>\n",
       "      <td>-0.689830</td>\n",
       "      <td>-0.769031</td>\n",
       "      <td>-0.552509</td>\n",
       "      <td>-0.208828</td>\n",
       "      <td>-0.644221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228305</td>\n",
       "      <td>-0.542700</td>\n",
       "      <td>-0.161703</td>\n",
       "      <td>-0.354453</td>\n",
       "      <td>-0.317485</td>\n",
       "      <td>-0.326763</td>\n",
       "      <td>-0.070641</td>\n",
       "      <td>-0.052818</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.500000</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>0.179963</td>\n",
       "      <td>-0.022248</td>\n",
       "      <td>-0.053468</td>\n",
       "      <td>-0.275168</td>\n",
       "      <td>0.040859</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029441</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>-0.011159</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>-0.052172</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.011288</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139298.000000</td>\n",
       "      <td>1.316068</td>\n",
       "      <td>0.800283</td>\n",
       "      <td>1.026960</td>\n",
       "      <td>0.739647</td>\n",
       "      <td>0.612218</td>\n",
       "      <td>0.396792</td>\n",
       "      <td>0.570474</td>\n",
       "      <td>0.325704</td>\n",
       "      <td>0.595977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186194</td>\n",
       "      <td>0.528245</td>\n",
       "      <td>0.147748</td>\n",
       "      <td>0.439738</td>\n",
       "      <td>0.350667</td>\n",
       "      <td>0.240261</td>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.078276</td>\n",
       "      <td>77.510000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean    94811.077600       0.005917      -0.004135       0.001613   \n",
       "std     47481.047891       1.948026       1.646703       1.508682   \n",
       "min         0.000000     -56.407510     -72.715728     -48.325589   \n",
       "25%     54204.750000      -0.915951      -0.600321      -0.889682   \n",
       "50%     84692.500000       0.020384       0.063949       0.179963   \n",
       "75%    139298.000000       1.316068       0.800283       1.026960   \n",
       "max    172792.000000       2.454930      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean       -0.002966       0.001828      -0.001139       0.001801   \n",
       "std         1.414184       1.377008       1.331931       1.227664   \n",
       "min        -5.683171    -113.743307     -26.160506     -43.557242   \n",
       "25%        -0.850134      -0.689830      -0.769031      -0.552509   \n",
       "50%        -0.022248      -0.053468      -0.275168       0.040859   \n",
       "75%         0.739647       0.612218       0.396792       0.570474   \n",
       "max        16.875344      34.801666      73.301626     120.589494   \n",
       "\n",
       "                  V8             V9  ...            V21            V22  \\\n",
       "count  283726.000000  283726.000000  ...  283726.000000  283726.000000   \n",
       "mean       -0.000854      -0.001596  ...      -0.000371      -0.000015   \n",
       "std         1.179054       1.095492  ...       0.723909       0.724550   \n",
       "min       -73.216718     -13.434066  ...     -34.830382     -10.933144   \n",
       "25%        -0.208828      -0.644221  ...      -0.228305      -0.542700   \n",
       "50%         0.021898      -0.052596  ...      -0.029441       0.006675   \n",
       "75%         0.325704       0.595977  ...       0.186194       0.528245   \n",
       "max        20.007208      15.594995  ...      27.202839      10.503090   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean        0.000198       0.000214      -0.000232       0.000149   \n",
       "std         0.623702       0.605627       0.521220       0.482053   \n",
       "min       -44.807735      -2.836627     -10.295397      -2.604551   \n",
       "25%        -0.161703      -0.354453      -0.317485      -0.326763   \n",
       "50%        -0.011159       0.041016       0.016278      -0.052172   \n",
       "75%         0.147748       0.439738       0.350667       0.240261   \n",
       "max        22.528412       4.584549       7.519589       3.517346   \n",
       "\n",
       "                 V27            V28         Amount          Class  \n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000  \n",
       "mean        0.001763       0.000547      88.472687       0.001667  \n",
       "std         0.395744       0.328027     250.399437       0.040796  \n",
       "min       -22.565679     -15.430084       0.000000       0.000000  \n",
       "25%        -0.070641      -0.052818       5.600000       0.000000  \n",
       "50%         0.001479       0.011288      22.000000       0.000000  \n",
       "75%         0.091208       0.078276      77.510000       0.000000  \n",
       "max        31.612198      33.847808   25691.160000       1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean duplicated rows\n",
    "df_cleaned = df_original.drop_duplicates()\n",
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple baseline model with decision tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df_cleaned[[\"V10\", \"V11\", \"V12\", \"V14\", \"V16\", \"V17\", \"V18\"]]\n",
    "y = df_cleaned[\"Class\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "print(\"Start Traning...\")\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>965.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>86560.905699</td>\n",
       "      <td>-2.200307</td>\n",
       "      <td>1.651245</td>\n",
       "      <td>-3.298940</td>\n",
       "      <td>2.148513</td>\n",
       "      <td>-1.525798</td>\n",
       "      <td>-0.730773</td>\n",
       "      <td>-2.540876</td>\n",
       "      <td>0.433975</td>\n",
       "      <td>-1.209436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215339</td>\n",
       "      <td>0.049894</td>\n",
       "      <td>-0.032659</td>\n",
       "      <td>-0.051498</td>\n",
       "      <td>0.041935</td>\n",
       "      <td>0.035321</td>\n",
       "      <td>0.116950</td>\n",
       "      <td>0.036297</td>\n",
       "      <td>112.076218</td>\n",
       "      <td>0.490155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48121.416550</td>\n",
       "      <td>5.295259</td>\n",
       "      <td>3.523269</td>\n",
       "      <td>5.974497</td>\n",
       "      <td>3.181847</td>\n",
       "      <td>4.050289</td>\n",
       "      <td>1.647392</td>\n",
       "      <td>5.519600</td>\n",
       "      <td>4.032161</td>\n",
       "      <td>2.311864</td>\n",
       "      <td>...</td>\n",
       "      <td>2.003625</td>\n",
       "      <td>0.976913</td>\n",
       "      <td>1.167593</td>\n",
       "      <td>0.564974</td>\n",
       "      <td>0.670954</td>\n",
       "      <td>0.488635</td>\n",
       "      <td>0.904484</td>\n",
       "      <td>0.404490</td>\n",
       "      <td>254.650928</td>\n",
       "      <td>0.500162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>406.000000</td>\n",
       "      <td>-30.552380</td>\n",
       "      <td>-10.979679</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-3.538179</td>\n",
       "      <td>-22.105532</td>\n",
       "      <td>-6.406267</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-41.044261</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.797604</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-19.254328</td>\n",
       "      <td>-2.659700</td>\n",
       "      <td>-4.781606</td>\n",
       "      <td>-1.189179</td>\n",
       "      <td>-7.263482</td>\n",
       "      <td>-1.869290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45501.000000</td>\n",
       "      <td>-2.785102</td>\n",
       "      <td>-0.230857</td>\n",
       "      <td>-4.865184</td>\n",
       "      <td>-0.276189</td>\n",
       "      <td>-1.690780</td>\n",
       "      <td>-1.532462</td>\n",
       "      <td>-2.918287</td>\n",
       "      <td>-0.235083</td>\n",
       "      <td>-2.294535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164481</td>\n",
       "      <td>-0.516242</td>\n",
       "      <td>-0.247452</td>\n",
       "      <td>-0.380576</td>\n",
       "      <td>-0.289125</td>\n",
       "      <td>-0.293871</td>\n",
       "      <td>-0.069161</td>\n",
       "      <td>-0.060246</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79668.000000</td>\n",
       "      <td>-0.769172</td>\n",
       "      <td>0.951569</td>\n",
       "      <td>-1.222810</td>\n",
       "      <td>1.212136</td>\n",
       "      <td>-0.503492</td>\n",
       "      <td>-0.644602</td>\n",
       "      <td>-0.650245</td>\n",
       "      <td>0.138190</td>\n",
       "      <td>-0.695263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142675</td>\n",
       "      <td>0.038631</td>\n",
       "      <td>-0.036560</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.058504</td>\n",
       "      <td>-0.018853</td>\n",
       "      <td>0.047434</td>\n",
       "      <td>0.036574</td>\n",
       "      <td>18.650000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>131948.000000</td>\n",
       "      <td>1.084043</td>\n",
       "      <td>2.664274</td>\n",
       "      <td>0.358117</td>\n",
       "      <td>4.090177</td>\n",
       "      <td>0.425877</td>\n",
       "      <td>-0.018103</td>\n",
       "      <td>0.268049</td>\n",
       "      <td>0.871446</td>\n",
       "      <td>0.256297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641211</td>\n",
       "      <td>0.576358</td>\n",
       "      <td>0.193731</td>\n",
       "      <td>0.382801</td>\n",
       "      <td>0.408814</td>\n",
       "      <td>0.356470</td>\n",
       "      <td>0.451243</td>\n",
       "      <td>0.208858</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172288.000000</td>\n",
       "      <td>2.366845</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>3.236927</td>\n",
       "      <td>12.114672</td>\n",
       "      <td>11.095089</td>\n",
       "      <td>9.146401</td>\n",
       "      <td>12.699095</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>4.874550</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>8.225555</td>\n",
       "      <td>1.196869</td>\n",
       "      <td>2.395505</td>\n",
       "      <td>2.745261</td>\n",
       "      <td>3.052358</td>\n",
       "      <td>1.779364</td>\n",
       "      <td>3684.620000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time          V1          V2          V3          V4  \\\n",
       "count     965.000000  965.000000  965.000000  965.000000  965.000000   \n",
       "mean    86560.905699   -2.200307    1.651245   -3.298940    2.148513   \n",
       "std     48121.416550    5.295259    3.523269    5.974497    3.181847   \n",
       "min       406.000000  -30.552380  -10.979679  -31.103685   -3.538179   \n",
       "25%     45501.000000   -2.785102   -0.230857   -4.865184   -0.276189   \n",
       "50%     79668.000000   -0.769172    0.951569   -1.222810    1.212136   \n",
       "75%    131948.000000    1.084043    2.664274    0.358117    4.090177   \n",
       "max    172288.000000    2.366845   22.057729    3.236927   12.114672   \n",
       "\n",
       "               V5          V6          V7          V8          V9  ...  \\\n",
       "count  965.000000  965.000000  965.000000  965.000000  965.000000  ...   \n",
       "mean    -1.525798   -0.730773   -2.540876    0.433975   -1.209436  ...   \n",
       "std      4.050289    1.647392    5.519600    4.032161    2.311864  ...   \n",
       "min    -22.105532   -6.406267  -43.557242  -41.044261  -13.434066  ...   \n",
       "25%     -1.690780   -1.532462   -2.918287   -0.235083   -2.294535  ...   \n",
       "50%     -0.503492   -0.644602   -0.650245    0.138190   -0.695263  ...   \n",
       "75%      0.425877   -0.018103    0.268049    0.871446    0.256297  ...   \n",
       "max     11.095089    9.146401   12.699095   20.007208    4.874550  ...   \n",
       "\n",
       "              V21         V22         V23         V24         V25         V26  \\\n",
       "count  965.000000  965.000000  965.000000  965.000000  965.000000  965.000000   \n",
       "mean     0.215339    0.049894   -0.032659   -0.051498    0.041935    0.035321   \n",
       "std      2.003625    0.976913    1.167593    0.564974    0.670954    0.488635   \n",
       "min    -22.797604   -8.887017  -19.254328   -2.659700   -4.781606   -1.189179   \n",
       "25%     -0.164481   -0.516242   -0.247452   -0.380576   -0.289125   -0.293871   \n",
       "50%      0.142675    0.038631   -0.036560    0.007684    0.058504   -0.018853   \n",
       "75%      0.641211    0.576358    0.193731    0.382801    0.408814    0.356470   \n",
       "max     27.202839    8.361985    8.225555    1.196869    2.395505    2.745261   \n",
       "\n",
       "              V27         V28       Amount       Class  \n",
       "count  965.000000  965.000000   965.000000  965.000000  \n",
       "mean     0.116950    0.036297   112.076218    0.490155  \n",
       "std      0.904484    0.404490   254.650928    0.500162  \n",
       "min     -7.263482   -1.869290     0.000000    0.000000  \n",
       "25%     -0.069161   -0.060246     1.750000    0.000000  \n",
       "50%      0.047434    0.036574    18.650000    0.000000  \n",
       "75%      0.451243    0.208858    99.990000    1.000000  \n",
       "max      3.052358    1.779364  3684.620000    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly undersampling the majority class to balance the dataset and quickly test the model\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_undersampled = resample(df_cleaned[df_cleaned.Class == 0], replace=False, n_samples=492, random_state=123)\n",
    "df_undersampled = pd.concat([df_undersampled, df_cleaned[df_cleaned.Class == 1]])\n",
    "df_undersampled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Traning...\n",
      "Confusion Matrix:\n",
      " [[83 12]\n",
      " [ 9 89]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89        95\n",
      "           1       0.88      0.91      0.89        98\n",
      "\n",
      "    accuracy                           0.89       193\n",
      "   macro avg       0.89      0.89      0.89       193\n",
      "weighted avg       0.89      0.89      0.89       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Only Select V10, V11, V12, V14, V16, V17, V18 freature to classify Class\n",
    "X_under = df_undersampled[[\"V10\", \"V11\", \"V12\", \"V14\", \"V16\", \"V17\", \"V18\"]]\n",
    "y_under = df_undersampled[\"Class\"]\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "print(\"Start Traning...\")\n",
    "# Train the classifier\n",
    "clf.fit(X_train_under, y_train_under)\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test_under)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_under, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_under, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampled Training and Cross Validation with Decision Tree, Random Forest, Pytorch Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers:  DecisionTreeClassifier Has a training score of 89.0 % accuracy score\n",
      "Classifiers:  RandomForestClassifier Has a training score of 93.0 % accuracy score\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train_under, y_train_under)\n",
    "    training_score = cross_val_score(classifier, X_train_under, y_train_under, cv=5)\n",
    "    print(\n",
    "        \"Classifiers: \",\n",
    "        classifier.__class__.__name__,\n",
    "        \"Has a training score of\",\n",
    "        round(training_score.mean(), 2) * 100,\n",
    "        \"% accuracy score\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GridSearchCV to find the best parameters.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# DecisionTree Classifier\n",
    "tree_params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": list(range(2, 4, 1)),\n",
    "    \"min_samples_leaf\": list(range(5, 7, 1)),\n",
    "}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\n",
    "grid_tree.fit(X_train_under, y_train_under)\n",
    "\n",
    "# tree best estimator\n",
    "tree_clf = grid_tree.best_estimator_\n",
    "\n",
    "# RandomForest Classifier\n",
    "forest_params = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": list(range(2, 4, 1)),\n",
    "    \"min_samples_leaf\": list(range(5, 7, 1)),\n",
    "}\n",
    "grid_forest = GridSearchCV(RandomForestClassifier(), forest_params)\n",
    "grid_forest.fit(X_train_under, y_train_under)\n",
    "\n",
    "# forest best estimator\n",
    "forest_clf = grid_forest.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Create a DataFrame with all the scores and the classifiers names.\n",
    "tree_pred = cross_val_predict(tree_clf, X_train_under, y_train_under, cv=5)\n",
    "forest_pred = cross_val_predict(forest_clf, X_train_under, y_train_under, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier ROC AUC validation score:  0.913329974811083\n",
      "Random Forest Classifier ROC AUC validation Score:  0.9193316540722082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "print(\"Decision Tree Classifier ROC AUC validation score: \", roc_auc_score(y_train_under, tree_pred))\n",
    "print(\"Random Forest Classifier ROC AUC validation Score: \", roc_auc_score(y_train_under, forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matri for Decision Tree:\n",
      " [[93  2]\n",
      " [11 87]]\n",
      "Classification Report for Decision Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        95\n",
      "           1       0.98      0.89      0.93        98\n",
      "\n",
      "    accuracy                           0.93       193\n",
      "   macro avg       0.94      0.93      0.93       193\n",
      "weighted avg       0.94      0.93      0.93       193\n",
      "\n",
      "Confusion Matri for Random Forest:\n",
      " [[94  1]\n",
      " [11 87]]\n",
      "Classification Report for Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        95\n",
      "           1       0.99      0.89      0.94        98\n",
      "\n",
      "    accuracy                           0.94       193\n",
      "   macro avg       0.94      0.94      0.94       193\n",
      "weighted avg       0.94      0.94      0.94       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with undersampled data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "tree_pred_test = tree_clf.predict(X_test_under)\n",
    "forest_pred_test = forest_clf.predict(X_test_under)\n",
    "\n",
    "print(\"Confusion Matri for Decision Tree:\\n\", confusion_matrix(y_test_under, tree_pred_test))\n",
    "print(\"Classification Report for Decision Tree:\\n\", classification_report(y_test_under, tree_pred_test))\n",
    "print(\"Confusion Matri for Random Forest:\\n\", confusion_matrix(y_test_under, forest_pred_test))\n",
    "print(\"Classification Report for Random Forest:\\n\", classification_report(y_test_under, forest_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matri for Decision Tree:\n",
      " [[54826  1830]\n",
      " [   13    77]]\n",
      "Classification Report for Decision Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     56656\n",
      "           1       0.04      0.86      0.08        90\n",
      "\n",
      "    accuracy                           0.97     56746\n",
      "   macro avg       0.52      0.91      0.53     56746\n",
      "weighted avg       1.00      0.97      0.98     56746\n",
      "\n",
      "Confusion Matri for Random Forest:\n",
      " [[55617  1039]\n",
      " [   14    76]]\n",
      "Classification Report for Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56656\n",
      "           1       0.07      0.84      0.13        90\n",
      "\n",
      "    accuracy                           0.98     56746\n",
      "   macro avg       0.53      0.91      0.56     56746\n",
      "weighted avg       1.00      0.98      0.99     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with original data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "tree_pred_test = tree_clf.predict(X_test)\n",
    "forest_pred_test = forest_clf.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matri for Decision Tree:\\n\", confusion_matrix(y_test, tree_pred_test))\n",
    "print(\"Classification Report for Decision Tree:\\n\", classification_report(y_test, tree_pred_test))\n",
    "print(\"Confusion Matri for Random Forest:\\n\", confusion_matrix(y_test, forest_pred_test))\n",
    "print(\"Classification Report for Random Forest:\\n\", classification_report(y_test, forest_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 0.7228, Validation Loss: 0.7038, Validation Accuracy: 0.5337, Validation F1: 0.0021\n",
      "Epoch [2/500], Loss: 0.7047, Validation Loss: 0.6869, Validation Accuracy: 0.5644, Validation F1: 0.0023\n",
      "Epoch [3/500], Loss: 0.6850, Validation Loss: 0.6665, Validation Accuracy: 0.6060, Validation F1: 0.0040\n",
      "Epoch [4/500], Loss: 0.6680, Validation Loss: 0.6508, Validation Accuracy: 0.6392, Validation F1: 0.0027\n",
      "Epoch [5/500], Loss: 0.6503, Validation Loss: 0.6329, Validation Accuracy: 0.6777, Validation F1: 0.0042\n",
      "Epoch [6/500], Loss: 0.6341, Validation Loss: 0.6179, Validation Accuracy: 0.7072, Validation F1: 0.0045\n",
      "Epoch [7/500], Loss: 0.6171, Validation Loss: 0.6005, Validation Accuracy: 0.7436, Validation F1: 0.0056\n",
      "Epoch [8/500], Loss: 0.6018, Validation Loss: 0.5870, Validation Accuracy: 0.7743, Validation F1: 0.0064\n",
      "Epoch [9/500], Loss: 0.5863, Validation Loss: 0.5699, Validation Accuracy: 0.8018, Validation F1: 0.0086\n",
      "Epoch [10/500], Loss: 0.5718, Validation Loss: 0.5588, Validation Accuracy: 0.8247, Validation F1: 0.0087\n",
      "Epoch [11/500], Loss: 0.5571, Validation Loss: 0.5454, Validation Accuracy: 0.8456, Validation F1: 0.0113\n",
      "Epoch [12/500], Loss: 0.5443, Validation Loss: 0.5273, Validation Accuracy: 0.8706, Validation F1: 0.0141\n",
      "Epoch [13/500], Loss: 0.5309, Validation Loss: 0.5177, Validation Accuracy: 0.8826, Validation F1: 0.0155\n",
      "Epoch [14/500], Loss: 0.5170, Validation Loss: 0.5061, Validation Accuracy: 0.8970, Validation F1: 0.0168\n",
      "Epoch [15/500], Loss: 0.5034, Validation Loss: 0.4914, Validation Accuracy: 0.9138, Validation F1: 0.0215\n",
      "Epoch [16/500], Loss: 0.4914, Validation Loss: 0.4805, Validation Accuracy: 0.9231, Validation F1: 0.0295\n",
      "Epoch [17/500], Loss: 0.4794, Validation Loss: 0.4684, Validation Accuracy: 0.9341, Validation F1: 0.0317\n",
      "Epoch [18/500], Loss: 0.4685, Validation Loss: 0.4573, Validation Accuracy: 0.9434, Validation F1: 0.0367\n",
      "Epoch [19/500], Loss: 0.4576, Validation Loss: 0.4459, Validation Accuracy: 0.9507, Validation F1: 0.0420\n",
      "Epoch [20/500], Loss: 0.4476, Validation Loss: 0.4349, Validation Accuracy: 0.9566, Validation F1: 0.0501\n",
      "Epoch [21/500], Loss: 0.4361, Validation Loss: 0.4263, Validation Accuracy: 0.9606, Validation F1: 0.0540\n",
      "Epoch [22/500], Loss: 0.4255, Validation Loss: 0.4157, Validation Accuracy: 0.9663, Validation F1: 0.0636\n",
      "Epoch [23/500], Loss: 0.4162, Validation Loss: 0.4073, Validation Accuracy: 0.9685, Validation F1: 0.0678\n",
      "Epoch [24/500], Loss: 0.4073, Validation Loss: 0.3946, Validation Accuracy: 0.9745, Validation F1: 0.0824\n",
      "Epoch [25/500], Loss: 0.3977, Validation Loss: 0.3877, Validation Accuracy: 0.9757, Validation F1: 0.0831\n",
      "Epoch [26/500], Loss: 0.3883, Validation Loss: 0.3773, Validation Accuracy: 0.9814, Validation F1: 0.1079\n",
      "Epoch [27/500], Loss: 0.3804, Validation Loss: 0.3711, Validation Accuracy: 0.9807, Validation F1: 0.1004\n",
      "Epoch [28/500], Loss: 0.3694, Validation Loss: 0.3619, Validation Accuracy: 0.9842, Validation F1: 0.1330\n",
      "Epoch [29/500], Loss: 0.3616, Validation Loss: 0.3530, Validation Accuracy: 0.9867, Validation F1: 0.1469\n",
      "Epoch [30/500], Loss: 0.3544, Validation Loss: 0.3491, Validation Accuracy: 0.9859, Validation F1: 0.1423\n",
      "Epoch [31/500], Loss: 0.3469, Validation Loss: 0.3379, Validation Accuracy: 0.9890, Validation F1: 0.1719\n",
      "Epoch [32/500], Loss: 0.3392, Validation Loss: 0.3340, Validation Accuracy: 0.9887, Validation F1: 0.1604\n",
      "Epoch [33/500], Loss: 0.3325, Validation Loss: 0.3245, Validation Accuracy: 0.9915, Validation F1: 0.2146\n",
      "Epoch [34/500], Loss: 0.3249, Validation Loss: 0.3167, Validation Accuracy: 0.9925, Validation F1: 0.2478\n",
      "Epoch [35/500], Loss: 0.3187, Validation Loss: 0.3098, Validation Accuracy: 0.9938, Validation F1: 0.2663\n",
      "Epoch [36/500], Loss: 0.3119, Validation Loss: 0.3050, Validation Accuracy: 0.9933, Validation F1: 0.2329\n",
      "Epoch [37/500], Loss: 0.3052, Validation Loss: 0.2998, Validation Accuracy: 0.9937, Validation F1: 0.2674\n",
      "Epoch [38/500], Loss: 0.2991, Validation Loss: 0.2930, Validation Accuracy: 0.9949, Validation F1: 0.3086\n",
      "Epoch [39/500], Loss: 0.2932, Validation Loss: 0.2865, Validation Accuracy: 0.9953, Validation F1: 0.2970\n",
      "Epoch [40/500], Loss: 0.2871, Validation Loss: 0.2809, Validation Accuracy: 0.9962, Validation F1: 0.3972\n",
      "Epoch [41/500], Loss: 0.2816, Validation Loss: 0.2735, Validation Accuracy: 0.9961, Validation F1: 0.3516\n",
      "Epoch [42/500], Loss: 0.2751, Validation Loss: 0.2703, Validation Accuracy: 0.9961, Validation F1: 0.3296\n",
      "Epoch [43/500], Loss: 0.2703, Validation Loss: 0.2649, Validation Accuracy: 0.9968, Validation F1: 0.4050\n",
      "Epoch [44/500], Loss: 0.2652, Validation Loss: 0.2598, Validation Accuracy: 0.9971, Validation F1: 0.4261\n",
      "Epoch [45/500], Loss: 0.2593, Validation Loss: 0.2549, Validation Accuracy: 0.9967, Validation F1: 0.3675\n",
      "Epoch [46/500], Loss: 0.2549, Validation Loss: 0.2481, Validation Accuracy: 0.9978, Validation F1: 0.4925\n",
      "Epoch [47/500], Loss: 0.2500, Validation Loss: 0.2456, Validation Accuracy: 0.9975, Validation F1: 0.4041\n",
      "Epoch [48/500], Loss: 0.2442, Validation Loss: 0.2399, Validation Accuracy: 0.9979, Validation F1: 0.4699\n",
      "Epoch [49/500], Loss: 0.2408, Validation Loss: 0.2357, Validation Accuracy: 0.9978, Validation F1: 0.4870\n",
      "Epoch [50/500], Loss: 0.2361, Validation Loss: 0.2311, Validation Accuracy: 0.9980, Validation F1: 0.5241\n",
      "Epoch [51/500], Loss: 0.2315, Validation Loss: 0.2277, Validation Accuracy: 0.9979, Validation F1: 0.4974\n",
      "Epoch [52/500], Loss: 0.2273, Validation Loss: 0.2238, Validation Accuracy: 0.9983, Validation F1: 0.5422\n",
      "Epoch [53/500], Loss: 0.2236, Validation Loss: 0.2200, Validation Accuracy: 0.9986, Validation F1: 0.6026\n",
      "Epoch [54/500], Loss: 0.2192, Validation Loss: 0.2157, Validation Accuracy: 0.9981, Validation F1: 0.5333\n",
      "Epoch [55/500], Loss: 0.2158, Validation Loss: 0.2115, Validation Accuracy: 0.9984, Validation F1: 0.5714\n",
      "Epoch [56/500], Loss: 0.2117, Validation Loss: 0.2078, Validation Accuracy: 0.9982, Validation F1: 0.5030\n",
      "Epoch [57/500], Loss: 0.2081, Validation Loss: 0.2048, Validation Accuracy: 0.9984, Validation F1: 0.5350\n",
      "Epoch [58/500], Loss: 0.2041, Validation Loss: 0.2001, Validation Accuracy: 0.9985, Validation F1: 0.5658\n",
      "Epoch [59/500], Loss: 0.2006, Validation Loss: 0.1976, Validation Accuracy: 0.9982, Validation F1: 0.4366\n",
      "Epoch [60/500], Loss: 0.1972, Validation Loss: 0.1940, Validation Accuracy: 0.9986, Validation F1: 0.5806\n",
      "Epoch [61/500], Loss: 0.1936, Validation Loss: 0.1897, Validation Accuracy: 0.9986, Validation F1: 0.5752\n",
      "Epoch [62/500], Loss: 0.1907, Validation Loss: 0.1876, Validation Accuracy: 0.9988, Validation F1: 0.6207\n",
      "Epoch [63/500], Loss: 0.1872, Validation Loss: 0.1833, Validation Accuracy: 0.9987, Validation F1: 0.5693\n",
      "Epoch [64/500], Loss: 0.1839, Validation Loss: 0.1801, Validation Accuracy: 0.9989, Validation F1: 0.6331\n",
      "Epoch [65/500], Loss: 0.1815, Validation Loss: 0.1786, Validation Accuracy: 0.9988, Validation F1: 0.5691\n",
      "Epoch [66/500], Loss: 0.1783, Validation Loss: 0.1751, Validation Accuracy: 0.9988, Validation F1: 0.5891\n",
      "Epoch [67/500], Loss: 0.1748, Validation Loss: 0.1713, Validation Accuracy: 0.9988, Validation F1: 0.6056\n",
      "Epoch [68/500], Loss: 0.1718, Validation Loss: 0.1692, Validation Accuracy: 0.9988, Validation F1: 0.5758\n",
      "Epoch [69/500], Loss: 0.1692, Validation Loss: 0.1666, Validation Accuracy: 0.9989, Validation F1: 0.6000\n",
      "Epoch [70/500], Loss: 0.1662, Validation Loss: 0.1635, Validation Accuracy: 0.9988, Validation F1: 0.5865\n",
      "Epoch [71/500], Loss: 0.1638, Validation Loss: 0.1606, Validation Accuracy: 0.9989, Validation F1: 0.6061\n",
      "Epoch [72/500], Loss: 0.1604, Validation Loss: 0.1584, Validation Accuracy: 0.9987, Validation F1: 0.5289\n",
      "Epoch [73/500], Loss: 0.1585, Validation Loss: 0.1547, Validation Accuracy: 0.9988, Validation F1: 0.5909\n",
      "Epoch [74/500], Loss: 0.1563, Validation Loss: 0.1522, Validation Accuracy: 0.9990, Validation F1: 0.6290\n",
      "Early stopping. No improvement in validation F1 for 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, dropout_prob):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_size1)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden_size2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df_cleaned[[\"V10\", \"V11\", \"V12\", \"V14\", \"V16\", \"V17\", \"V18\"]]\n",
    "y = df_cleaned[\"Class\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "n_inputs = X_train.shape[1]\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
    "\n",
    "\n",
    "hidden_size1 = 64\n",
    "hidden_size2 = 32\n",
    "output_size = 2\n",
    "dropout_prob = 0.3\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the ImprovedModel\n",
    "model = Model(n_inputs, hidden_size1, hidden_size2, output_size, dropout_prob)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# Training loop\n",
    "epochs = 500\n",
    "patience = 10  # Number of epochs without improvement before early stopping\n",
    "best_val_accuracy = 0.0\n",
    "best_val_f1 = 0.0\n",
    "counter = 0\n",
    "early_stop_threshold = 0.001\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "        val_accuracy = accuracy_score(y_val_tensor, val_outputs.argmax(dim=1).numpy())\n",
    "        val_f1 = f1_score(y_val_tensor, val_outputs.argmax(dim=1).numpy())\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation F1: {val_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    if val_f1 - best_val_f1 > early_stop_threshold:\n",
    "        best_val_f1 = val_f1\n",
    "        counter = 0  # Reset counter\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping. No improvement in validation F1 for {} epochs.\".format(patience))\n",
    "        break  # Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9989\n",
      "Precision: 0.7885\n",
      "Recall: 0.4556\n",
      "F1 Score: 0.5775\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56656\n",
      "           1       0.79      0.46      0.58        90\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.89      0.73      0.79     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "Confusion Matrix:\n",
      "[[56645    11]\n",
      " [   49    41]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "# Convert the test data from Pandas DataFrames to NumPy arrays\n",
    "\n",
    "# Create PyTorch tensors from the NumPy arrays\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Pass the test data through the trained model to obtain predictions\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "\n",
    "# Calculate the predicted labels\n",
    "predicted_labels = test_outputs.argmax(dim=1).numpy()\n",
    "\n",
    "# Calculate the accuracy on the test data\n",
    "test_accuracy = accuracy_score(y_test_tensor, predicted_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test_tensor, predicted_labels)\n",
    "recall = recall_score(y_test_tensor, predicted_labels)\n",
    "f1 = f1_score(y_test_tensor, predicted_labels)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test_tensor, predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Generate and print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_tensor, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbm301",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
